# ################################################################################
# purpose: Run tasks in postgres
# status: WORKING
#
docker stop c-python
docker rm c-python
docker rmi i-python
#
# build
docker build -t i-python .
#
# run
docker run -d --name c-python --network n-raogaru -v ./scripts:/app/scripts -v ./data:/app/data i-python tail -f /dev/null
#
docker stop c-python
docker start c-python
#
# connect
docker exec -it c-python /bin/sh
#
# --------------------------------------------------------------------------------
# test
docker exec -it c-python /bin/sh

#
# create ddl scripts - for the purpose of running tasks on postgres. 
vLINE="################################################################################"
# --------------------------------------------------------------------------------
# tabgen.py - genrate ddl scripts and dml scripts based on tabgen.yaml
# repat for job1 to job5
for DIRNAME in job1 job2 job3 job4 job5 part_list part_hash part_range part_random
do
echo ${vLINE}
#vi scripts/job1/tabgen.yaml
docker exec -it c-python tabgen.py scripts/${DIRNAME}/tabgen.yaml
done

# In postgres create schemas job0...job5 part_list part_hash part_range part_random
docker exec -it c-postgres /bin/sh
su - postgres
\i postgres.sql

# --------------------------------------------------------------------------------
# jobrun.py - execute scripts in postgres based on jobrun.yaml
# execute jobs - which will create tables in postgres
for DIRNAME in sample job1 job2 job3 job4 job5 part_list part_hash part_range part_random
do
echo ${vLINE}
docker exec -it c-python jobrun.py scripts/${DIRNAME}/jobrun.yaml
docker exec -it c-python jobrun.py scripts/${DIRNAME}/cleanup.yaml
done
# --------------------------------------------------------------------------------
# csvgen.py - generate csvfiles based on csvgen.yaml
docker exec -it c-python /bin/sh
csvgen.py random		# choose random columns from yaml file
csvgen.py product		# choose columns pre-defined in yaml file
csvgen.py product --config csvgen.yaml
csvgen.py product --config csvgen.yaml --files 10
docker exec -it c-python /app/bin/csvgen.py product --files 10

for TABLE in  person address customer product order
do
docker exec -it c-python /app/bin/csvgen.py ${TABLE} --files 10
done
# --------------------------------------------------------------------------------
# csvstat.py - read csvfiles (generated by csvgen.py and provide stats on numeric columns)
docker exec -it c-python /bin/sh
Usage: csvstat.py <column_number> <csv-files-prefix>
csvstat.py 3 data/csv/x_product_
docker exec -it c-python /app/bin/csvstat.py 3 data/csv/product_
# --------------------------------------------------------------------------------
# csvstat2.py - read csvstat2.yaml. connect to postgres. read table column_names and data types and generate csv

docker exec -it c-python /bin/sh
csvstat.py 3 data/csv/product_

docker exec -it c-python /app/bin/csvstat.py 3 data/csv/product_

# --------------------------------------------------------------------------------
# pgdatacomp.py - read pgdatacomp.yaml - connect to source and target postgres databases

docker exec -it c-python pgdatacomp.py 

# --------------------------------------------------------------------------------
# sql query to check number of tables by schema
SELECT
    n.nspname AS schema_name,
    COUNT(*)  AS table_count
FROM pg_class c
JOIN pg_namespace n ON n.oid = c.relnamespace
WHERE c.relkind IN ('r', 'p')              -- regular + partitioned tables
  AND n.nspname NOT IN ('pg_catalog', 'information_schema')
GROUP BY n.nspname
ORDER BY n.nspname;

select count(1) from public.rdb_jobrun_log;


# ################################################################################
